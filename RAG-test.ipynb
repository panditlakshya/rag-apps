{
 "cells": [
  {
   "cell_type": "raw",
   "id": "88722002-ffae-40f2-b321-d01b1058aa67",
   "metadata": {},
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9408bdb4-d712-4f2e-b3e9-83ecff289563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f3765d-76ab-4eee-90e5-e64a2c3ee99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dcd7044-d15e-42aa-87af-69b08e17416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d9d23af-a7dd-414b-9907-2386fc9a265d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 24, 'total_tokens': 28, 'completion_time': 0.003333333, 'prompt_time': 0.003042843, 'queue_time': 0.011163746, 'total_time': 0.006376176}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0095bce-8658-43f6-b065-a993fa2b2130-0', usage_metadata={'input_tokens': 24, 'output_tokens': 4, 'total_tokens': 28})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe60a01f-3d0d-43c4-be7a-9f8afb7e7435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's the translation:\\n\\nतुम्हारो नाम के हो? (Tumhārō nām ke ho?)\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 28, 'total_tokens': 59, 'completion_time': 0.025833333, 'prompt_time': 0.004827974, 'queue_time': 0.11693614000000001, 'total_time': 0.030661307}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None}, id='run-35647344-c8de-4c5f-a6e5-d24ea7226dcc-0', usage_metadata={'input_tokens': 28, 'output_tokens': 31, 'total_tokens': 59})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Nepali\"),\n",
    "    HumanMessage(content=\"What is your name?\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1885140-68f0-4619-8bac-1590df1bdd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40eadee-0cfb-4d6d-9035-d8b130eeb108",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "457cc492-2b6e-432e-a7f7-f2baa64972db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'तुम्हारो नाम के हो? (Tumhārō nām kē ho?)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75c3ef24-69c1-4bf6-9e0c-3d1c6c1ded3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bd5f4da-3854-4c40-aa26-ea87c90f5859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into italian:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84c8ad53-af5e-4bb1-8924-5427dec3f0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Ciao caro\"\\n\\n(Note: \"Ciao\" is a casual way to say \"hello\" in Italian, and \"caro\" means \"dear\" or \"beloved\". If you want to use a more formal tone, you can say \"Ciao egregio\" or \"Ciao gentile\", which translates to \"Hello dear sir\" or \"Hello dear lady\".)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | model | parser\n",
    "chain.invoke({\"language\": \"italian\", \"text\": \"hello dear\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01c8799-6c54-4e49-a127-8dadb93900f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohappyeyeballs==2.4.3\n",
      "aiohttp==3.10.10\n",
      "aiosignal==1.3.1\n",
      "annotated-types==0.7.0\n",
      "anyio==4.4.0\n",
      "appnope==0.1.4\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.3.0\n",
      "asttokens==2.4.1\n",
      "async-lru==2.0.4\n",
      "attrs==23.2.0\n",
      "Babel==2.15.0\n",
      "beautifulsoup4==4.12.3\n",
      "bleach==6.1.0\n",
      "certifi==2024.7.4\n",
      "cffi==1.16.0\n",
      "charset-normalizer==3.3.2\n",
      "comm==0.2.2\n",
      "debugpy==1.8.2\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "distro==1.9.0\n",
      "executing==2.0.1\n",
      "fastjsonschema==2.20.0\n",
      "fqdn==1.5.1\n",
      "frozenlist==1.4.1\n",
      "groq==0.11.0\n",
      "h11==0.14.0\n",
      "hatch-jupyter-builder==0.9.1\n",
      "hatch-nodejs-version==0.3.2\n",
      "hatchling==1.25.0\n",
      "httpcore==1.0.5\n",
      "httpx==0.27.0\n",
      "idna==3.7\n",
      "ipykernel==6.29.5\n",
      "ipython==8.26.0\n",
      "isoduration==20.11.0\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.4\n",
      "json5==0.9.25\n",
      "jsonpatch==1.33\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.22.0\n",
      "jsonschema-specifications==2023.12.1\n",
      "jupyter-console==6.6.3\n",
      "jupyter-events==0.10.0\n",
      "jupyter-lsp==2.2.5\n",
      "jupyter_client==8.6.2\n",
      "jupyter_core==5.7.2\n",
      "jupyter_server==2.14.1\n",
      "jupyter_server_terminals==0.5.3\n",
      "jupyterlab==4.2.3\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.27.2\n",
      "langchain==0.3.3\n",
      "langchain-core==0.3.10\n",
      "langchain-groq==0.2.0\n",
      "langchain-text-splitters==0.3.0\n",
      "langsmith==0.1.134\n",
      "MarkupSafe==2.1.5\n",
      "matplotlib-inline==0.1.7\n",
      "mistune==3.0.2\n",
      "multidict==6.1.0\n",
      "nbclient==0.10.0\n",
      "nbconvert==7.16.4\n",
      "nbformat==5.10.4\n",
      "nest_asyncio==1.6.0\n",
      "notebook==7.2.1\n",
      "notebook_shim==0.2.4\n",
      "numpy==1.26.4\n",
      "orjson==3.10.7\n",
      "overrides==7.7.0\n",
      "packaging==24.1\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.4\n",
      "pathspec==0.12.1\n",
      "pexpect==4.9.0\n",
      "platformdirs==4.2.2\n",
      "pluggy==1.5.0\n",
      "prometheus_client==0.20.0\n",
      "prompt_toolkit==3.0.47\n",
      "propcache==0.2.0\n",
      "psutil==6.0.0\n",
      "ptyprocess==0.7.0\n",
      "pure_eval==0.2.2\n",
      "pycparser==2.22\n",
      "pydantic==2.9.2\n",
      "pydantic_core==2.23.4\n",
      "Pygments==2.18.0\n",
      "python-dateutil==2.9.0.post0\n",
      "python-json-logger==2.0.7\n",
      "PyYAML==6.0.1\n",
      "pyzmq==26.0.3\n",
      "referencing==0.35.1\n",
      "requests==2.32.3\n",
      "requests-toolbelt==1.0.0\n",
      "rfc3339_validator==0.1.4\n",
      "rfc3986_validator==0.1.1\n",
      "rpds-py==0.18.1\n",
      "Send2Trash==1.8.3\n",
      "setuptools==70.2.0\n",
      "six==1.16.0\n",
      "sniffio==1.3.1\n",
      "soupsieve==2.5\n",
      "SQLAlchemy==2.0.35\n",
      "stack_data==0.6.3\n",
      "tenacity==8.5.0\n",
      "terminado==0.18.1\n",
      "tinycss2==1.3.0\n",
      "tornado==6.4.1\n",
      "traitlets==5.14.3\n",
      "trove-classifiers==2024.7.2\n",
      "types-python-dateutil==2.9.0.20240316\n",
      "typing_extensions==4.12.2\n",
      "uri-template==1.3.0\n",
      "urllib3==2.2.2\n",
      "wcwidth==0.2.13\n",
      "webcolors==24.6.0\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "wheel @ file:///opt/homebrew/Cellar/python%403.12/3.12.4/libexec/wheel-0.43.0-py3-none-any.whl#sha256=ff23205a590f2b902a2a21151019e96b93ab4a1409d7c9748b6bd210f4c0f44d\n",
      "yarl==1.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33bcd635-801e-498a-b7b6-ac3460e1d5bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The python kernel does not appear to be a conda environment.  Please use ``%pip install`` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages/IPython/core/magics/packaging.py:26\u001b[0m, in \u001b[0;36mis_conda_environment.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# TODO: does this need to change on windows?\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe python kernel does not appear to be a conda environment.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use ``\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mpip install`` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: The python kernel does not appear to be a conda environment.  Please use ``%pip install`` instead."
     ]
    }
   ],
   "source": [
    "conda list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
